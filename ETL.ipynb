{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se importan las bibliotecas necesarias para el manejo de los datos, para la carga debemos tener en cuenta que los archivos se encuentran en JSON y queremos convertirlos en un Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import json as js\n",
    "import ast as ast\n",
    "import re\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el Dataset de steam_games, se pudo utilizar el pd.read para la carga de sus datos y funcionó correctamente. Los Datasets de user_reviews y user_items al contener listas anidadas en sus celdas, se tuvo que proceder con un código diferente: Se crea una lista vacía y se utiliza un bucle for para leer cada línea del archivo JSON, convertirla a un diccionario de Python y agregarla a la lista. Finalmente, la lista se convierte en un DataFrame de Pandas usando pd.DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.read_json('output_steam_games.json', lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_rev = []\n",
    "archivo1 = r'australian_user_reviews.json'\n",
    "with open(archivo1, encoding='utf-8') as file:\n",
    "    for line in file.readlines():\n",
    "        list_rev.append(ast.literal_eval(line))\n",
    "\n",
    "reviews = pd.DataFrame(list_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_items = []\n",
    "archivo2 = r'australian_users_items.json'\n",
    "with open(archivo2, encoding='utf-8') as file:\n",
    "    for line in file.readlines():\n",
    "        list_items.append(ast.literal_eval(line))\n",
    "\n",
    "items = pd.DataFrame(list_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desanidación de tablas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos las tablas cargadas, pero se puede observar que los Dataframes de Reviews e Items contienen ambos una columna con listas anidadas ('reviews' e 'items'), se procede entonces a la desanidación de estas para poder trabajar con el Dataframe de la manera más optima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.explode('reviews', ignore_index=True)\n",
    "reviews_expanded = pd.json_normalize(reviews['reviews'])\n",
    "reviews_expanded=reviews_expanded.replace('',None)\n",
    "reviews = reviews.join(reviews_expanded)\n",
    "reviews.drop(columns=['reviews'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = items.explode('items', ignore_index=True)\n",
    "items_expanded = pd.json_normalize(items['items'])\n",
    "items_expanded = items_expanded.replace('', None)\n",
    "items = items.join(items_expanded)\n",
    "items.drop(columns=['items'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminación de columnas innecesarias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de leer todas las consultas y exigencias del proyecto a realizar, se pudo llegar a la conclusión de cuales columnas serán utiles y cuales no, basados en esto, podemos proceder a eliminar las columnas que NO van a ser de algún uso para este análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = games.drop(columns=['publisher', 'title', 'url', 'reviews_url','specs','early_access'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.drop(columns=['user_url', 'funny', 'posted', 'last_edited', 'helpful'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = items.drop(columns=['items_count', 'steam_id', 'user_url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El análisis se realizó con df.isnull().sum() \n",
    "- El Dataframe Games contiene 88310 filas con todas sus celdas en Nan, todas estas serán eliminadas del Dataframe; los valores faltantes de las filas restantes las cuales contienen información serán tratadas en las siguientes secciones.\n",
    "- El Dataframe Reviews contiene 4 columnas y 28 filas con valores nulos en 3 de sus columnas, estas serán eliminadas ya que no nos brindan ninguna información.\n",
    "- El Dataframe Items contiene 16806 filas con 4 de 5 columnas en Nan, estás serán eliminadas ya que no contienen ninguna información valiosa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = games.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.dropna(thresh=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = items.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores faltantes y Tipo de dato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Dataframe Games contiene valores que deben ser normalizados, corregidos y rellenados. A continuación todos los procedimientos que se le realizaron:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. La columna Price contiene muchas celdas en string, las cuales en su mayoría deberían ser 0.00, ya que aluden a juegos que son 'Free To Play'. A excepción de 2 precios los cuales si contienen un valor especifico (499.00 y 449.00), estos serán corregidos por su valor numerico correspondiente y el resto de strings serán convertidos en 0.00. Ya teniendo todos los valores de la columna Price en tipo numerico puede ser modificado su tipo de dato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "games['price'] = games['price'].replace('Starting at $499.00', 499.00)\n",
    "games['price'] = games['price'].replace('Starting at $449.00', 449.00)\n",
    "\n",
    "mask = games['price'].apply(lambda x: isinstance(x, str))\n",
    "games.loc[mask, 'price'] = 0.00\n",
    "\n",
    "# Se le agrega el errors para las celdas que contienen None\n",
    "games['price'] = pd.to_numeric(games['price'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. La columna Release_date contiene la fecha de lanzamiento de los juegos, vienen muchos formatos dentro de esta que deberán ser normalizados, meses en texto, estaciones del año...Se construyo entonces una función para todos los casos detectados y poder convertir esta columna en tipo de dato fecha, para posteriormente extraer el año (Se necesita para las consultas) y cambiar el nombre de la columna por 'year'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_fecha(fecha):\n",
    "    # Formatos Mes año, mes año, año...\n",
    "    for fmt in ['%B %Y', '%b %Y', '%Y-%m-%d', '%Y']:\n",
    "        try:\n",
    "            return pd.to_datetime(fecha, format=fmt)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    # Casos donde hay texto antes del año\n",
    "    match = re.search(r'\\b(\\d{4})\\b', fecha)\n",
    "    if match:\n",
    "        # Si encuentra un año, convertirlo\n",
    "        return pd.to_datetime(match.group(1), format='%Y')\n",
    "\n",
    "    return pd.NaT  # Si no coincide con ningún formato, devuelve NaT\n",
    "\n",
    "# Aplicar la función de conversión\n",
    "games['release_date'] = games['release_date'].apply(convertir_fecha)\n",
    "\n",
    "# Extraer el año\n",
    "games['release_date'] = games['release_date'].dt.year\n",
    "\n",
    "# Cambio de nombre de la columna release_date\n",
    "games = games.rename(columns={'release_date': 'year'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Las columnas 'app_name' e 'id' serán renombradas para que coincidan con los nombres de las columnas de las tablas Reviews e Items, esto con el fin de poder hacer un 'merged' o 'join' en las consultas posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = games.rename(columns={'app_name': 'item_name'})\n",
    "\n",
    "games = games.rename(columns={'id': 'item_id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Se necesita hacer el cambio de tipo de dato a dos columnas: 'item_id' y 'year', para las consultas posteriores...pero esto requiere que no existan valores en None, por ende se tomó la decisión de convertirlos en 0.00 para posteriormente hacer el cambio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "games['item_id'] = games['item_id'].fillna(0)\n",
    "games['item_id'] = games['item_id'].astype(int)\n",
    "\n",
    "games['year'] = games['year'].fillna(0)\n",
    "games['year'] = games['year'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Dataframe Items, necesita cambiar el tipo de dato de item_id para poder hacer merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "items['item_id'] = items['item_id'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de tener los Dataframes ya limpios, se procede por último a borrar las filas exactamente iguales. Ahora los Datasets están listos para ser trabajados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = games.drop_duplicates(subset=['item_name', 'year', 'price', 'item_id', 'developer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = items.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de Sentimiento con NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función realizada aquí se centra en analizar el sentimiento sobre cada fila, basándose en dos campos: review (reseña) y recommend (si el usuario recomienda o no el juego).Si la reseña está vacía, utiliza la recomendación del usuario para determinar el sentimiento (positivo o negativo). Si la reseña está presente, usa la polaridad del texto con TextBlob para clasificar la reseña como positiva, negativa o neutral, y guarda el resultado en la columna de review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_sentimiento(row):\n",
    "    reseña = row['review']\n",
    "    recomendacion = row['recommend']\n",
    "    \n",
    "    # Caso: la reseña está vacía\n",
    "    if pd.isnull(reseña) or reseña.strip() == '':\n",
    "        # Si no hay reseña, usar la recomendación para determinar el sentimiento\n",
    "        if recomendacion:\n",
    "            return 2  # Si recomienda el juego, asignar positivo\n",
    "        else:\n",
    "            return 0  # Si no recomienda el juego, asignar negativo\n",
    "    \n",
    "    # Si la reseña está presente, hacer el análisis de sentimiento\n",
    "    analysis = TextBlob(reseña).sentiment.polarity\n",
    "    \n",
    "    # Asignar el sentimiento basado en la polaridad\n",
    "    if analysis < -0.1:\n",
    "        return 0  # Sentimiento negativo\n",
    "    elif analysis > 0.1:\n",
    "        return 2  # Sentimiento positivo\n",
    "    else:\n",
    "        return 1  # Neutral\n",
    "\n",
    "# Aplicar la función al dataset\n",
    "reviews['review'] = reviews.apply(analizar_sentimiento, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar los archivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se instala la librería pyarrow y se guardan los archivos ya tratados y limpios en formato tipo Parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta especifica donde quiero guardar los archivos parquet\n",
    "ruta_games = 'C:\\\\Users\\\\Sarita\\\\Desktop\\\\SOY HENRY\\\\Proyecto 1\\\\games_cleaned.parquet'\n",
    "ruta_reviews = 'C:\\\\Users\\\\Sarita\\\\Desktop\\\\SOY HENRY\\\\Proyecto 1\\\\reviews_cleaned.parquet'\n",
    "ruta_items = 'C:\\\\Users\\\\Sarita\\\\Desktop\\\\SOY HENRY\\\\Proyecto 1\\\\items_cleaned.parquet'\n",
    "\n",
    "# Guarda el DataFrame en formato parquet en la ruta especificada\n",
    "games.to_parquet(ruta_games, index=False)\n",
    "reviews.to_parquet(ruta_reviews, index=False)\n",
    "items.to_parquet(ruta_items, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Archivos Render"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que es una aplicación gratuita de poca memoria disponible y se necesitan probar las consultas realizadas, se hará entonces con una muestra representativa de los Dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define el tamaño de la muestra (5% de las filas)\n",
    "sample_fraction = 0.05\n",
    "\n",
    "# Cargar los DataFrames completos\n",
    "games_sample = games.sample(frac=sample_fraction, random_state=42)\n",
    "reviews_sample = reviews.sample(frac=sample_fraction, random_state=42)\n",
    "items_sample = items.sample(frac=sample_fraction, random_state=42)\n",
    "\n",
    "# Guardar las muestras en archivos Parquet\n",
    "games_sample.to_parquet('games_sample.parquet')\n",
    "reviews_sample.to_parquet('reviews_sample.parquet')\n",
    "items_sample.to_parquet('items_sample.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1607 entries, 93213 to 110765\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   genres     1457 non-null   object \n",
      " 1   item_name  1607 non-null   object \n",
      " 2   year       1607 non-null   int64  \n",
      " 3   tags       1601 non-null   object \n",
      " 4   price      1543 non-null   float64\n",
      " 5   item_id    1607 non-null   int64  \n",
      " 6   developer  1448 non-null   object \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 100.4+ KB\n"
     ]
    }
   ],
   "source": [
    "games_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 254705 entries, 1784637 to 3695348\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   user_id           254705 non-null  object \n",
      " 1   item_id           254705 non-null  int64  \n",
      " 2   item_name         254705 non-null  object \n",
      " 3   playtime_forever  254705 non-null  float64\n",
      " 4   playtime_2weeks   254705 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 11.7+ MB\n"
     ]
    }
   ],
   "source": [
    "items_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2922 entries, 11926 to 8576\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   user_id    2922 non-null   object\n",
      " 1   item_id    2922 non-null   object\n",
      " 2   recommend  2922 non-null   object\n",
      " 3   review     2922 non-null   int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 114.1+ KB\n"
     ]
    }
   ],
   "source": [
    "reviews_sample.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_sample.columns = games_sample.columns.str.strip()\n",
    "items_sample.columns = items_sample.columns.str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_sample = games_sample.drop_duplicates(subset=\"item_name\")\n",
    "items_sample = items_sample.drop_duplicates(subset=\"item_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_sample = games_sample.dropna(subset=[\"item_name\"])\n",
    "items_sample = items_sample.dropna(subset=[\"item_name\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
